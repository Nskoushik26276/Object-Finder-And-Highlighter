ğŸ§  Open-Vocabulary Object Detection with OWLâ€‘ViT
This project demonstrates open-vocabulary object detection using the OWLâ€‘ViT model from Google.
Unlike traditional object detectors limited to fixed classes, OWLâ€‘ViT can detect any object you describe in text, even if it wasnâ€™t seen during training.
ğŸ” Features:
Upload any image.
Enter one or multiple text prompts (e.g., temple, umbrella, person).
The model draws bounding boxes around detected objects matching your prompts.
Uses a low detection threshold to catch smaller or less obvious objects.
âš™ï¸ Technologies used:
Transformers (by Hugging Face) for the OWLâ€‘ViT model and processor.
PyTorch for deep learning.
PIL and Matplotlib for drawing and visualization.
Google Colab for running interactively in the browser.
âœ¨ This notebook shows how powerful open-vocabulary models can be, as they arenâ€™t limited to fixed classes like COCO or ImageNet â€” making them ideal for detecting rare, custom, or domain-specific objects.
ğŸ§ª Usage guide
âœ… Open the notebook in Google Colab.
âœ… Upload any image youâ€™d like to analyze.
âœ… Enter comma-separated prompts like:
plaintext
Copy
Edit
umbrella, person, temple
âœ… The model will:
Predict bounding boxes for each object matching your prompts.
Display the image with highlighted boxes and scores.
Save the result as detected_result.jpg.


